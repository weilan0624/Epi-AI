{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.utils import resample\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from imblearn.ensemble import EasyEnsembleClassifier\n",
    "from imblearn.ensemble import BalancedBaggingClassifier\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "import os  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(file_dir):   \n",
    "    pickle_L=[]   \n",
    "    pickle_name=[]\n",
    "    for dirpath, dirnames, filenames in os.walk(file_dir):  \n",
    "        for file in filenames :  \n",
    "            if os.path.splitext(file)[1] == '.pickle':  \n",
    "                pickle_L.append(os.path.join(dirpath, file))  \n",
    "                pickle_name.append(os.path.join(file))  \n",
    "            \n",
    "    #return L \n",
    "    return  pickle_name\n",
    "    #return name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickleLoader(pklFile):\n",
    "    try:\n",
    "        while True:\n",
    "            yield pickle.load(pklFile)\n",
    "    except EOFError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_path='Epi-AI_processed_files/Train/Model_I/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_file=read_pickle(tra_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame1=[]\n",
    "for i in range(0,len(train_file)):\n",
    "    with open(tra_path+train_file[i],'rb') as file:\n",
    "        #print(file)\n",
    "        for event in pickleLoader(file):\n",
    "            train_frame1.append(event)\n",
    "\n",
    "train_re1= pd.concat(train_frame1, ignore_index=True)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_com1=train_re1[['target','mean_EEG2', 'EEG2_mobility', 'TKEO_EEG2', 'EEG2_P_delta','EEG2_P_theta',\n",
    "                                'EEG2_P_alpha','EEG2_P_beta','EEG2_P_gamma','EEG2_P_total','EEG2_rel_delta','EEG2_rel_theta',\n",
    "                                'EEG2_rel_alpha','EEG2_rel_beta','EEG2_rel_gamma','EEG2_pfd','EEG2_skew',\n",
    "                                'EEG2_kurtosis','EEG2_var','EEG2_envelope']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_path2='Epi-AI_processed_files/Train/Model_II/'\n",
    "train_file2=read_pickle(tra_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame2=[]\n",
    "for i in range(0,len(train_file2)):\n",
    "    with open(tra_path2+train_file2[i],'rb') as file2:\n",
    "        #print(file)\n",
    "        for event2 in pickleLoader(file2):\n",
    "            train_frame2.append(event2)\n",
    "train_re2= pd.concat(train_frame2, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_com2=train_re2[['target','mean_EEG2', 'EEG2_mobility', 'TKEO_EEG2', 'EEG2_P_delta','EEG2_P_theta',\n",
    "                                'EEG2_P_alpha','EEG2_P_beta','EEG2_P_gamma','EEG2_P_total','EEG2_rel_delta','EEG2_rel_theta',\n",
    "                                'EEG2_rel_alpha','EEG2_rel_beta','EEG2_rel_gamma','EEG2_pfd','EEG2_skew',\n",
    "                                'EEG2_kurtosis','EEG2_var','EEG2_envelope']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tra_path3='Epi-AI_processed_files/Train/Model_III/'\n",
    "train_file3=read_pickle(tra_path3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_frame3=[]\n",
    "for i in range(0,len(train_file3)):\n",
    "    with open(tra_path3+train_file3[i],'rb') as file3:\n",
    "        #print(file)\n",
    "        for event3 in pickleLoader(file3):\n",
    "            train_frame3.append(event3)\n",
    "train_re3= pd.concat(train_frame3, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_com3=train_re3[['target','mean_EEG2', 'EEG2_mobility', 'TKEO_EEG2', 'EEG2_P_delta','EEG2_P_theta',\n",
    "                                'EEG2_P_alpha','EEG2_P_beta','EEG2_P_gamma','EEG2_P_total','EEG2_rel_delta','EEG2_rel_theta',\n",
    "                                'EEG2_rel_alpha','EEG2_rel_beta','EEG2_rel_gamma','EEG2_pfd','EEG2_skew',\n",
    "                                'EEG2_kurtosis','EEG2_var','EEG2_envelope']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [train_com1, train_com2, train_com3]\n",
    "\n",
    "data_train = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data_train.target\n",
    "X = data_train.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split( X ,y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# xgboost for feature importance on a classification problem\n",
    "from xgboost import XGBClassifier\n",
    "from matplotlib import pyplot\n",
    "# define the model\n",
    "model = XGBClassifier(\n",
    "     learning_rate =0.01,\n",
    "     n_estimators=100,\n",
    "     max_depth=6,\n",
    "     scale_pos_weight=478, \n",
    "     random_state=2)\n",
    "# fit the model\n",
    "model.fit(X_train, y_train)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "#from sklearn.externals import joblib\n",
    "#filename = 'JNE_XG_W478.sav'\n",
    "#joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n",
    "threshold=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#load model\n",
    "filename='JNE_XG_W478.sav'\n",
    "\n",
    "model=joblib.load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tra = y_train\n",
    "X_tra = X_train\n",
    "#pred_y_1 =model.predict(X_1)\n",
    "predicted_proba = model.predict_proba(X_tra)\n",
    "pred_y_tra = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_tra, pred_y_tra))\n",
    "print(\"ROC : \", roc_auc_score(y_tra,pred_y_tra))\n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_tra,pred_y_tra))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_tra, pred_y_tra,digits=4))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_tra,pred_y_tra).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "sens=tp/(tp+fn)\n",
    "\n",
    "print('Sens: ', sens )\n",
    "print('Specificity:', specificity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns=['mean', 'mobility','TKEO', 'absolute delta power','absolute theta power',\n",
    "               'absolute alpha power','absolute beta power','absolute gamma power','absolute total power',\n",
    "               'relative delta power','relative theta power','relative alpha power','relative beta power',\n",
    "               'relative gamma power','fractal dimension','skewness',\n",
    "                'kurtosis','variance','signal envelope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t = y_test\n",
    "X_t = X_test\n",
    "#pred_y_1 =model.predict(X_1)\n",
    "predicted_proba = model.predict_proba(X_t)\n",
    "pred_y_t = (predicted_proba [:,1] >= threshold).astype('int')\n",
    "\n",
    "print(\"Accuracy: \", metrics.accuracy_score(y_t, pred_y_t))\n",
    "print(\"ROC : \", roc_auc_score(y_t,pred_y_t)) \n",
    "print(\"Confusion matrix: \\n\", metrics.confusion_matrix(y_t,pred_y_t))\n",
    "print(\"Classification report:\\n \", metrics.classification_report(y_t, pred_y_t,digits=4))\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(y_t,pred_y_t).ravel()\n",
    "specificity = tn / (tn+fp)\n",
    "sens=tp/(tp+fn)\n",
    "\n",
    "print('Sens: ', sens )\n",
    "print('Specificity:', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
