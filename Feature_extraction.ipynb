{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pyedflib\n",
    "#!pip install PyWavelets\n",
    "\n",
    "import pyedflib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import pywt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from numpy import *\n",
    "from scipy.signal import *\n",
    "from numpy.fft import * \n",
    "from matplotlib import *\n",
    "from scipy import *\n",
    "from pylab import *\n",
    "import pandas\n",
    "from scipy.fftpack import fft,ifft\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.signal as signal\n",
    "from scipy import fftpack\n",
    "import math\n",
    "import pyedflib\n",
    "import pyeeg\n",
    "import pywt\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pylab import *\n",
    "\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "from numpy.fft import * \n",
    "import scipy\n",
    "from scipy.signal import *\n",
    "from scipy import *\n",
    "from scipy.fftpack import fft,ifft\n",
    "import scipy.signal as signal\n",
    "from scipy import fftpack\n",
    "\n",
    "import io\n",
    "import struct\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pickle(file_dir):   \n",
    "    pickle_L=[]   \n",
    "    pickle_name=[]\n",
    "    for dirpath, dirnames, filenames in os.walk(file_dir):  \n",
    "        for file in filenames :  \n",
    "            if os.path.splitext(file)[1] == '.edf':  \n",
    "                pickle_L.append(os.path.join(dirpath, file))  \n",
    "                pickle_name.append(os.path.join(file))  \n",
    "            \n",
    "    return pickle_L \n",
    "    #return  pickle_name\n",
    "    #return name\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "def file_name(file_dir):   \n",
    "    L=[]   \n",
    "    name=[]\n",
    "    for dirpath, dirnames, filenames in os.walk(file_dir):  \n",
    "        for file in filenames :  \n",
    "            if os.path.splitext(file)[1] =='.edf':  \n",
    "                L.append(os.path.join(dirpath, file))  \n",
    "                name.append(os.path.splitext(file)[0])  \n",
    "            \n",
    "    #return L \n",
    "    return name\n",
    "    #return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  \n",
    "import pandas as pd\n",
    "def edf_file(file_dir):   \n",
    "    L=[]   \n",
    "    R=[]\n",
    "    for dirpath, dirnames, filenames in os.walk(file_dir):  \n",
    "        for file in filenames :  \n",
    "            if os.path.splitext(file)[1] == '.edf':  \n",
    "                L.append(os.path.join(dirpath, file))  \n",
    "                R.append(os.path.join(file))\n",
    "                #name.append(os.path.splitext(file)[0])  \n",
    "            \n",
    "    #return L \n",
    "    return R\n",
    "    #return name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=\"file_path\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "la = \"file_path\\\\\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_fil=read_pickle(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnname=edf_file(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new=file_name(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "na=[]\n",
    "for i in range(0,len(new)):\n",
    "    na.append(new[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sub-Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import hilbert, chirp\n",
    "from scipy.signal import butter, lfilter\n",
    "import pyeeg\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=6):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=6):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y\n",
    "\n",
    "epoch=int(0.5*250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overlap window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=500\n",
    "epoch=int(2.5*fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_stack(a, stepsize=1, width=2):\n",
    "    n = a.shape[0]\n",
    "    return np.hstack( a[i:1+n+i-width:stepsize] for i in range(0,width) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (0, len(pickle_fil)):\n",
    "    edf_file=read_pickle(p)[i]\n",
    "    signals, signal_headers, header =pyedflib.highlevel.read_edf(edf_file)\n",
    "    f = pyedflib.EdfReader(edf_file)\n",
    "    print(f)\n",
    "    n = f.signals_in_file\n",
    "    signal_labels = f.getSignalLabels()\n",
    "    new_signal_label=[]\n",
    "    sigbufs = np.zeros((n, f.getNSamples()[0]))\n",
    "\n",
    "    for p in np.arange(2):\n",
    "        sigbufs[p, :] = f.readSignal(p)\n",
    "    df_signals = pd.DataFrame(sigbufs)\n",
    "    df_signals = df_signals.transpose()\n",
    "    #df_signals.columns = signal_labels\n",
    "    df_signals.columns=['EEG1','EEG2']\n",
    "    \n",
    "    #df = df.transpose()\n",
    "    #df.columns = signal_labels\n",
    "    #fs1=f.getSampleFrequency(3)\n",
    "    #print(fs1)\n",
    "   # res = signal.resample(df,int(len(df)/fs1*250))\n",
    "    #df_signals =pd.DataFrame(res)\n",
    "    #df_signals.columns = new_signal_label\n",
    "    \n",
    "    df_signals['Annotation']=0    \n",
    "    manual=df_signals['Annotation']\n",
    "    \n",
    "    df_signals=df_signals['EEG2']-mean(df_signals['EEG2'])\n",
    "    df_signals=pd.DataFrame(df_signals)\n",
    "    df_signals.columns=['EEG2']\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Notch filter \n",
    "    f0 = 50.0  # Frequency to be removed from signal (Hz)\n",
    "    #Q = 15.0  # Quality factor\n",
    "    Q=35\n",
    "    # Design notch filter\n",
    "    b, a = signal.iirnotch(f0, Q,fs)\n",
    "\n",
    "    freq, h = signal.freqz(b, a)\n",
    "\n",
    "    n = len(df_signals)                  # length of the signal\n",
    "    k = np.arange(n)\n",
    "    T = n/fs\n",
    "    frq = k/T                   # two sides frequency range\n",
    "    frq1 = frq[range(int(n/2))] # one side frequency range\n",
    "\n",
    "\n",
    "    df_EEG2=pd.DataFrame(signal.filtfilt(b, a, df_signals['EEG2'], method='gust'))\n",
    "\n",
    "    df_EEG2_notch=df_EEG2[0]\n",
    "\n",
    "    # mean \n",
    "    R_reshape=pd.DataFrame(np.array(df_EEG2_notch).reshape(int(n/epoch),-1))\n",
    "    R_overlap=pd.DataFrame(window_stack(R_reshape, stepsize=1, width=2))\n",
    "    R_t=R_overlap.T\n",
    "\n",
    "    mean_EEG2=R_t.mean()\n",
    "\n",
    "    # TKEO\n",
    "    signal_EEG2 = df_EEG2_notch.to_numpy()\n",
    "\n",
    "    # [Application of TKEO Operator]\n",
    "    tkeo_EEG2 = []\n",
    "\n",
    "\n",
    "    for iii in range(0, len(signal_EEG2)):\n",
    "        if iii == 0 or iii== (len(signal_EEG2 ) - 1):\n",
    "            tkeo_EEG2.append(signal_EEG2[iii])\n",
    "\n",
    "        else:\n",
    "            tkeo_EEG2.append((signal_EEG2[iii]** 2) - (signal_EEG2[iii + 1] * signal_EEG2[iii - 1]))\n",
    "\n",
    "    EEG2_tkeo=pd.DataFrame(np.array(tkeo_EEG2).reshape(int(n/epoch),-1))\n",
    "    EEG2_tkeo_overlap=pd.DataFrame(window_stack(EEG2_tkeo, stepsize=1, width=2))\n",
    "    TKE_EEG2=EEG2_tkeo_overlap.T\n",
    "    TKEO_EEG2=mean(TKE_EEG2)\n",
    "\n",
    "\n",
    "    # Frequency\n",
    "    EEG2_P_delta=(butter_bandpass_filter(mean_EEG2, 0.1, 4, fs, order=6))**2\n",
    "    EEG2_P_theta=(butter_bandpass_filter(mean_EEG2, 4, 8, fs, order=6))**2\n",
    "    EEG2_P_alpha=(butter_bandpass_filter(mean_EEG2, 8, 16, fs, order=6))**2\n",
    "    EEG2_P_beta=(butter_bandpass_filter(mean_EEG2, 16, 32, fs, order=6))**2\n",
    "    EEG2_P_gamma=(butter_bandpass_filter(mean_EEG2, 32, 64, fs, order=6))**2\n",
    "\n",
    "    EEG2_P_total=mean_EEG2**2\n",
    "    EEG2_rel_delta=EEG2_P_delta/EEG2_P_total\n",
    "    EEG2_rel_theta=EEG2_P_theta/EEG2_P_total\n",
    "    EEG2_rel_alpha=EEG2_P_alpha/EEG2_P_total\n",
    "    EEG2_rel_beta=EEG2_P_beta/EEG2_P_total;\n",
    "    EEG2_rel_gamma=EEG2_P_gamma/EEG2_P_total;\n",
    "\n",
    "\n",
    "    EEG2_P_delta=pd.DataFrame(EEG2_P_delta)\n",
    "    EEG2_P_theta=pd.DataFrame(EEG2_P_theta)\n",
    "    EEG2_P_alpha=pd.DataFrame(EEG2_P_alpha)\n",
    "    EEG2_P_beta=pd.DataFrame(EEG2_P_beta)\n",
    "    EEG2_P_gamma=pd.DataFrame(EEG2_P_gamma)\n",
    "    EEG2_P_total=pd.DataFrame(EEG2_P_total)\n",
    "    EEG2_rel_delta=pd.DataFrame(EEG2_rel_delta)\n",
    "    EEG2_rel_theta=pd.DataFrame(EEG2_rel_theta)\n",
    "    EEG2_rel_alpha=pd.DataFrame(EEG2_rel_alpha)\n",
    "    EEG2_rel_beta=pd.DataFrame(EEG2_rel_beta)\n",
    "    EEG2_rel_gamma=pd.DataFrame(EEG2_rel_gamma)\n",
    "\n",
    "\n",
    "    analytic_EEG2 = hilbert(mean_EEG2)\n",
    "    EEG2_envelope = np.abs(analytic_EEG2)\n",
    "    EEG2_envelope = pd.DataFrame(EEG2_envelope)\n",
    "\n",
    "\n",
    "\n",
    "    R1=[]\n",
    "    p1=[]\n",
    "    skew1=[]\n",
    "    kur1=[]\n",
    "    var1=[]\n",
    "\n",
    "    for i1 in range(0,R_t.shape[1]):\n",
    "        R1.append(pyeeg.hjorth(R_t[i1].values.tolist(), D=None))\n",
    "        p1.append(pyeeg.pfd(R_t[i1].values.tolist()))\n",
    "        ### SKEWNESS\n",
    "        skew1.append(scipy.stats.skew(R_t[i1].values.tolist(), axis=0, bias=True))\n",
    "        ### Kurtosis\n",
    "        kur1.append(scipy.stats.kurtosis(R_t[i1].values.tolist()))\n",
    "        ### VARIANCE\n",
    "        var1.append(numpy.var(R_t[i1].values.tolist(), axis=None, dtype=None, out=None, ddof=0))\n",
    "\n",
    "\n",
    "\n",
    "    hjR1=pd.DataFrame(np.asarray(R1))\n",
    "    EEG2_mobility=pd.DataFrame(hjR1[0])\n",
    "    #R_hurst=pd.DataFrame(np.asarray(h1))\n",
    "    EEG2_pfd=pd.DataFrame(np.asarray(p1))\n",
    "    #R_hfd=pd.DataFrame(np.asarray(hf1))\n",
    "    EEG2_skew=pd.DataFrame(np.asarray(skew1))\n",
    "    EEG2_kurtosis=pd.DataFrame(np.asarray(kur1))\n",
    "    EEG2_var=pd.DataFrame(np.asarray(var1))  \n",
    "\n",
    "    # target\n",
    "    label=pd.read_excel('label/'+str(na[i])+'.xlsx')\n",
    "\n",
    "    label[['S_hour','S_minute','S_second']]=label['start'].str.split('.',expand=True)\n",
    "    label[['E_hour','E_minute','E_second']]=label['end'].str.split('.',expand=True)\n",
    "\n",
    "    label['S_hour']=label['S_hour'].astype(int)\n",
    "    label['S_minute']=label['S_minute'].astype(int)\n",
    "    label['S_second']=label['S_second'].astype(int)\n",
    "    label['E_hour']=label['E_hour'].astype(int)\n",
    "    label['E_minute']=label['E_minute'].astype(int)\n",
    "    label['E_second']=label['E_second'].astype(int)\n",
    "\n",
    "    label['Start_signal']=(label['S_hour']*3600+label['S_minute']*60+label['S_second'])*500\n",
    "    label['End_signal']=(label['E_hour']*3600+label['E_minute']*60+label['E_second'])*500\n",
    "    label['Duration']=label['End_signal']-label['Start_signal']\n",
    "\n",
    "    for ppppp in range(0,len(label)):\n",
    "        manual[label.Start_signal.values[ppppp]:label.End_signal.values[ppppp]]=1\n",
    "\n",
    "    mark_reshape=pd.DataFrame(np.array(manual).reshape(int(n/epoch),-1))\n",
    "    mark_overlape=pd.DataFrame(window_stack(mark_reshape, stepsize=1, width=2))\n",
    "    mark_tar=mark_overlape.T    \n",
    "\n",
    "    sp_tar=pd.DataFrame(sum(mark_tar))\n",
    "    sp_tar.columns=['seizure']\n",
    "\n",
    "    sp_tar.loc[sp_tar['seizure']>=epoch, 'target'] = 1\n",
    "    sp_tar.loc[sp_tar['seizure']<epoch, 'target'] = 0\n",
    "    sp_tar['target'] = sp_tar['target'].astype('int')\n",
    "\n",
    "    target=sp_tar['target']\n",
    "    \n",
    "    df_combine = pd.concat([target,mean_EEG2, EEG2_mobility, TKEO_EEG2, EEG2_P_delta,EEG2_P_theta,\n",
    "                            EEG2_P_alpha,EEG2_P_beta,EEG2_P_gamma,EEG2_P_total,EEG2_rel_delta,EEG2_rel_theta,\n",
    "                            EEG2_rel_alpha,EEG2_rel_beta,EEG2_rel_gamma,EEG2_pfd,EEG2_skew,\n",
    "                            EEG2_kurtosis,EEG2_var,EEG2_envelope], axis=1)\n",
    "    #data\n",
    "    df_combine.columns = ['target','mean_EEG2', 'EEG2_mobility', 'TKEO_EEG2', 'EEG2_P_delta','EEG2_P_theta',\n",
    "                                'EEG2_P_alpha','EEG2_P_beta','EEG2_P_gamma','EEG2_P_total','EEG2_rel_delta','EEG2_rel_theta',\n",
    "                                'EEG2_rel_alpha','EEG2_rel_beta','EEG2_rel_gamma','EEG2_pfd','EEG2_skew',\n",
    "                                'EEG2_kurtosis','EEG2_var','EEG2_envelope']\n",
    "\n",
    "    df1=open(\"filename_\"+str(na[i])+'.pickle','wb')# 注意一定要写明是wb 而不是w.\n",
    "    #最关键的是这步，将内容装入打开的文件之中（内容，目标文件）\n",
    "    pickle.dump(df_combine,df1)\n",
    "    df1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
